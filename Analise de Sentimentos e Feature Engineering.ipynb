{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22cf1e4d",
   "metadata": {},
   "source": [
    "Este dataset trata-se de dados de companhias aéreas dos EUA que contêm comentários de passageiros com base no serviço prestado pelas companhias aéreas no Twitter.\n",
    "O link pode ser acessado em: https://www.kaggle.com/datasets/welkin10/airline-sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aabc41",
   "metadata": {},
   "source": [
    "\n",
    "# Dicionário de Dados - \n",
    "\n",
    "- **tweet_id**: Identificador único para cada tweet.\n",
    "- **airline_sentiment**: Sentimento do tweet em relação à companhia aérea, podendo ser positivo, negativo ou neutro.\n",
    "- **airline_sentiment_confidence**: Grau de confiança no sentimento atribuído ao tweet, variando de 0 a 1, onde 1 indica alta confiança.\n",
    "- **negativereason**: Razão fornecida para o tweet ser classificado como negativo.\n",
    "- **negativereason_confidence**: Grau de confiança na razão fornecida para o tweet ser classificado como negativo, com valores variando de 0 a .\n",
    "- **airline**: Nome da companhia aérea a qual o tweet se refere.\n",
    "- **airline_sentiment_gold**: Sentimento atribuído ao tweet por um avaliador humano de alta confiança (padrão ouro).\n",
    "- **name**: Nome do usuário que postou o tweet.\n",
    "- **negativereason_gold**: Razão negativa atribuída ao tweet por um avaliador humano de alta confiança (padrão ouro).\n",
    "- **retweet_count**: Número de vezes que o tweet foi retweetado.\n",
    "- **text**: Texto do tweet.\n",
    "- **tweet_coord**: Coordenadas geográficas de onde o tweet foi postado.\n",
    "- **tweet_created**: Data e hora de criação do tweet.\n",
    "- **tweet_location**: Localização mencionada no perfil do usuário no momento da postagem do tweet.\n",
    "- **user_timezone**: Fuso horário do usuário que postou o tweet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c95c1a",
   "metadata": {},
   "source": [
    "**1 - Selecionar um conjunto de dados de análise de sentimentos binários disponível em qualquer base de dados online, excluindo aqueles abordados em aula e no TP2. Implementar as técnicas de TF-IDF, Bag-of-Words e Bag-of-nGrams para análise dos dados. Ao concluir, apresentar uma análise dos resultados obtidos. Caso o conjunto de dados apresente desbalanceamento, solicita-se a utilização de métricas adicionais além da acurácia para avaliar o desempenho dos modelos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcd9de16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\giova\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importações necessárias\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257562b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"tweets.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bef9657e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7111edbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecionado as colunas relevantes\n",
    "df = df[['text', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecf071f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1c931b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    9087\n",
      "neutral     3067\n",
      "positive    2298\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['airline_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0e4986",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removando registros 'neutral' de 'airline_sentiment'\n",
    "df = df[df['airline_sentiment'] != 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d06d053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative    9087\n",
      "positive    2298\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['airline_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f48c340",
   "metadata": {},
   "source": [
    "Obs: Com base nos resultados acima, observamos que (após a filtragem) possuímos um conjunto desbalanceado onde 9087 menções enquadram-se como **negativo** e 2298 como **positivo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b601fa65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 0\n",
       "airline_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Verificando valores NaN\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5328564",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo a coluna airline sentment em binário\n",
    "df['airline_sentiment'] = df['airline_sentiment'].map({'negative': 0, 'positive': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b716ab94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    9087\n",
      "1    2298\n",
      "Name: airline_sentiment, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['airline_sentiment'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32de89b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Iniciando o lematizador e stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Função para limpeza e lematização do texto\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+|\\@\\w+|\\#', '', text) # Removendo URLs, menções e hashtags com regex\n",
    "    text = re.sub(r'\\W', ' ', text).lower() # Removendo caracteres não alfanuméricos e convertendo para minúsculas\n",
    "    text = \" \".join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words]) # Lematizando e removendo stopwords\n",
    "    return text\n",
    "\n",
    "#Aplicando a função\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f558fe57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>1</td>\n",
       "      <td>plus added commercial experience tacky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>0</td>\n",
       "      <td>really aggressive blast obnoxious entertainmen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>0</td>\n",
       "      <td>really big bad thing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>0</td>\n",
       "      <td>seriously would pay 30 flight seat playing rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>1</td>\n",
       "      <td>yes nearly every time fly vx ear worm go away</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14633</th>\n",
       "      <td>@AmericanAir my flight was Cancelled Flightled...</td>\n",
       "      <td>0</td>\n",
       "      <td>flight cancelled flightled leaving tomorrow mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14634</th>\n",
       "      <td>@AmericanAir right on cue with the delays👌</td>\n",
       "      <td>0</td>\n",
       "      <td>right cue delay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>@AmericanAir thank you we got on a different f...</td>\n",
       "      <td>1</td>\n",
       "      <td>thank got different flight chicago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>@AmericanAir leaving over 20 minutes Late Flig...</td>\n",
       "      <td>0</td>\n",
       "      <td>leaving 20 minute late flight warning communic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14638</th>\n",
       "      <td>@AmericanAir you have my money, you change my ...</td>\n",
       "      <td>0</td>\n",
       "      <td>money change flight answer phone suggestion ma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11385 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  airline_sentiment  \\\n",
       "1      @VirginAmerica plus you've added commercials t...                  1   \n",
       "3      @VirginAmerica it's really aggressive to blast...                  0   \n",
       "4      @VirginAmerica and it's a really big bad thing...                  0   \n",
       "5      @VirginAmerica seriously would pay $30 a fligh...                  0   \n",
       "6      @VirginAmerica yes, nearly every time I fly VX...                  1   \n",
       "...                                                  ...                ...   \n",
       "14633  @AmericanAir my flight was Cancelled Flightled...                  0   \n",
       "14634         @AmericanAir right on cue with the delays👌                  0   \n",
       "14635  @AmericanAir thank you we got on a different f...                  1   \n",
       "14636  @AmericanAir leaving over 20 minutes Late Flig...                  0   \n",
       "14638  @AmericanAir you have my money, you change my ...                  0   \n",
       "\n",
       "                                              clean_text  \n",
       "1                 plus added commercial experience tacky  \n",
       "3      really aggressive blast obnoxious entertainmen...  \n",
       "4                                   really big bad thing  \n",
       "5      seriously would pay 30 flight seat playing rea...  \n",
       "6          yes nearly every time fly vx ear worm go away  \n",
       "...                                                  ...  \n",
       "14633  flight cancelled flightled leaving tomorrow mo...  \n",
       "14634                                    right cue delay  \n",
       "14635                 thank got different flight chicago  \n",
       "14636  leaving 20 minute late flight warning communic...  \n",
       "14638  money change flight answer phone suggestion ma...  \n",
       "\n",
       "[11385 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7d3ebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo os dados em treino e teste\n",
    "X = df['clean_text']\n",
    "y = df['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a032326",
   "metadata": {},
   "source": [
    "**Obs:** Agora, iremos vetorizar o texto aplicando as 3 técnicas propostas: Bag-of-Words, TF-IDF e Bag-of-nGrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cadaabf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo o treino e teste com Bag-of_words\n",
    "vectorizer_bow = CountVectorizer()\n",
    "X_train_bow = vectorizer_bow.fit_transform(X_train)\n",
    "X_test_bow = vectorizer_bow.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "457a6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo o treino e teste com TF-IDF\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer_tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer_tfidf.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b68bc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividindo o treino e teste com Bag-of-nGrams\n",
    "vectorizer_ngrams = CountVectorizer(ngram_range=(1, 2))  \n",
    "X_train_ngrams = vectorizer_ngrams.fit_transform(X_train)\n",
    "X_test_ngrams = vectorizer_ngrams.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c471f34",
   "metadata": {},
   "source": [
    "Agora iremos aplicar um modelo de Regressão Logística em cada uma das técnicas abordadas acima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90fccfef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avaliação do Modelo com Bag-of-Words\n",
      "Acurácia: 0.9073342116820378\n",
      "Precisão: 0.8075\n",
      "Recall: 0.7067833698030634\n",
      "F1-Score: 0.7537922987164527\n"
     ]
    }
   ],
   "source": [
    "#Modelo com Bag of words\n",
    "model_bow = LogisticRegression(max_iter = 1000)\n",
    "model_bow.fit(X_train_bow, y_train)\n",
    "\n",
    "#Realizando as predições\n",
    "y_pred_bow = model_bow.predict(X_test_bow)\n",
    "\n",
    "print(\"Avaliação do Modelo com Bag of Words\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_bow))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_bow))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_bow))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b03d8da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliação do Modelo com TF-IDF\n",
      "Acurácia: 0.8959156785243741\n",
      "Precisão: 0.8819444444444444\n",
      "Recall: 0.5557986870897156\n",
      "F1-Score: 0.6818791946308725\n"
     ]
    }
   ],
   "source": [
    "#Modelo com TF-IDF\n",
    "model_tfidf = LogisticRegression(max_iter=1000)\n",
    "model_tfidf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "#Realizando as prdedições\n",
    "y_pred_tfidf = model_tfidf.predict(X_test_tfidf)\n",
    "\n",
    "print(\"\\nAvaliação do Modelo com TF-IDF\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_tfidf))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_tfidf))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f1ed8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Avaliação do Modelo com Bag of nGrams\n",
      "Acurácia: 0.9073342116820378\n",
      "Precisão: 0.8360655737704918\n",
      "Recall: 0.6695842450765864\n",
      "F1-Score: 0.7436208991494532\n"
     ]
    }
   ],
   "source": [
    "#Mmodelo com Bagof nGrams\n",
    "model_ngrams = LogisticRegression(max_iter=1000)\n",
    "model_ngrams.fit(X_train_ngrams, y_train)\n",
    "\n",
    "#Realuzando as predições\n",
    "y_pred_ngrams = model_ngrams.predict(X_test_ngrams)\n",
    "\n",
    "print(\"\\nAvaliação do Modelo com Bag of nGrams\")\n",
    "print(\"Acurácia:\", accuracy_score(y_test, y_pred_ngrams))\n",
    "print(\"Precisão:\", precision_score(y_test, y_pred_ngrams))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred_ngrams))\n",
    "print(\"F1-Score:\", f1_score(y_test, y_pred_ngrams))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de7bd52",
   "metadata": {},
   "source": [
    "**Conclusões sobre o exercício 1:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81aa0383",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
